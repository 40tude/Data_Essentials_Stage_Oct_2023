{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing Template Lite\n",
    "1. Import lib\n",
    "1. Import data\n",
    "1. EDA - Exploratory Data Analysis\n",
    "1. Separate target and features\n",
    "1. Split train set and test set (80/20)\n",
    "1. Cleaning\n",
    "    1. Replace missing val\n",
    "    1. Standardize numerical features + One hot encode categorical variables\n",
    "    1. Encode labels of y\n",
    "1. Apply pre processing to test set\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"assets/ML/Data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - EDA - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 4)\n",
      "       Country        Age        Salary Purchased\n",
      "count       10   9.000000      9.000000        10\n",
      "unique       3        NaN           NaN         2\n",
      "top     France        NaN           NaN        No\n",
      "freq         4        NaN           NaN         5\n",
      "mean       NaN  38.777778  63777.777778       NaN\n",
      "std        NaN   7.693793  12265.579662       NaN\n",
      "min        NaN  27.000000  48000.000000       NaN\n",
      "25%        NaN  35.000000  54000.000000       NaN\n",
      "50%        NaN  38.000000  61000.000000       NaN\n",
      "75%        NaN  44.000000  72000.000000       NaN\n",
      "max        NaN  50.000000  83000.000000       NaN\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)                       # (#rows, #columns)\n",
    "print(df.describe(include=\"all\"))\n",
    "\n",
    "# Vérifier que le count est identique pour toutes les colonnes\n",
    "# Attention on peut avoir le même nb de valeurs qui manquent partout\n",
    "# Faut correler avec df.shape\n",
    "\n",
    "# Here, there are tons of options \n",
    "  # df.value_counts()\n",
    "  # df = df.drop(columns=[\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"])\n",
    "  # sns.catplot(data = df, x=\"Sex\", y=\"Survived\", kind=\"bar\")\n",
    "  # print(df[df['Embarked'].isna()]) # print lines with NaN\n",
    "  # df.isna().sum() / len(df) * 100 # print nb of Nana as %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voir par exemple que ici :\n",
    "* Y a des valeurs manquantes pour toutes les colonnes (count pas identique partout)\n",
    "* 3 catégories uniques de pays\n",
    "* target (purchased) de type Yes/No"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Separate Target from feature variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = [\"Country\", \"Age\", \"Salary\"]\n",
    "X = df.loc[:, features_list]\n",
    "y = df.loc[:, \"Purchased\"]\n",
    "# print(X.head())\n",
    "# print(y.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Train / Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usually : 80% training and 20% testing  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=0,       # donne une valeur pour être sûr d'avoir toujours le même comportement random\n",
    "                                                    stratify=y)           # Allows you to stratify our sample. \n",
    "                                                                          # We will have the same proportion of categories in test and train set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Cleaning\n",
    "\n",
    "1. Remplace missing values - SimpleImputer avec strategy='mean' pour valeurs numériques ou strategy='mode' si il manque des données catégorielles\n",
    "1. Standardize numerical features + One hot encode categorical variables\n",
    "1. If y is discrete => Encode labels of y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 - Replace missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Country   Age   Salary\n",
      "0   France  44.0  72000.0\n",
      "4  Germany  40.0      NaN\n",
      "6    Spain   NaN  52000.0\n",
      "9   France  37.0  67000.0\n",
      "3    Spain  38.0  61000.0\n",
      "1    Spain  27.0  48000.0\n",
      "2  Germany  30.0  54000.0\n",
      "5   France  35.0  58000.0\n",
      "\n",
      "   Country        Age        Salary\n",
      "0   France  44.000000  72000.000000\n",
      "4  Germany  40.000000  58857.142857\n",
      "6    Spain  35.857143  52000.000000\n",
      "9   France  37.000000  67000.000000\n",
      "3    Spain  38.000000  61000.000000\n",
      "1    Spain  27.000000  48000.000000\n",
      "2  Germany  30.000000  54000.000000\n",
      "5   France  35.000000  58000.000000\n"
     ]
    }
   ],
   "source": [
    "# Missing values - SimpleImputer\n",
    "# Si il avait manqué un nom de pays, on aurait pu utiliser une strategie \"mode\" pour remplacer par le pays le plus fréquent\n",
    "print(X_train)\n",
    "imputer = SimpleImputer(strategy=\"mean\")  # Instanciate class of SimpleImputer with strategy of mean\n",
    "#X_train = X_train.copy()                 # ! Copy dataset to avoid caveats of assign a copy of a slice of a DataFrame\n",
    "                                          # Semble plus nécessaire en 2023\n",
    "                                          # More info here https://towardsdatascience.com/explaining-the-settingwithcopywarning-in-pandas-ebc19d799d25\n",
    "\n",
    "X_train.iloc[:,[1,2]] = imputer.fit_transform(X_train.iloc[:,[1,2]]) # Fit and transform columns where there are missing values\n",
    "print() \n",
    "print(X_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 - Standardize numerical features + One hot encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00  0.00000000e+00  1.61706195e+00  1.78674463e+00]\n",
      " [ 1.00000000e+00  0.00000000e+00  8.22715727e-01  0.00000000e+00]\n",
      " [ 0.00000000e+00  1.00000000e+00 -1.41104234e-15 -9.32214592e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00  2.26956063e-01  1.10700483e+00]\n",
      " [ 0.00000000e+00  1.00000000e+00  4.25542617e-01  2.91317060e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Standardizing numeric features and encoding categorical features\n",
    "\n",
    "numeric_features = [1, 2]                             # On crée une liste avec les indices des colonnes qui contiennent des valeurs numériques\n",
    "                                                      # Age et Salaires sont dans les colonnes 1 et 2\n",
    "numeric_transformer = StandardScaler()                # On précise le type de transformer qu'on veut utiliser pour les val numériques\n",
    "\n",
    "categorical_features = [0]                            # On crée une liste avec les indices des colonnes qui contiennent des valeurs catégorielles\n",
    "                                                      # Les pays sont dans la colonne d'indice 0 (la première)\n",
    "categorical_transformer = OneHotEncoder(drop='first') # Pour virer l'Angleterre comme dans l'exemple ci-dessus on aurait mis drop=\"last\" mais ça n'existe pas\n",
    "                                                      # Il faut garder le drop first car sinon on a 2 colonnes \n",
    "                                                      # qui sont 100% corrélées est c'est pas bon pour le modèle\n",
    "\n",
    "featureencoder = ColumnTransformer(                   # ColumnTransformer provient du module compose\n",
    "    transformers=[                                    # On passe une liste de transformers à qui ont donne un nom (cat, num...)\n",
    "        ('cat', categorical_transformer, categorical_features),   \n",
    "        ('num', numeric_transformer, numeric_features)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# La variable featureencoder est un object de type ColumnTransformer\n",
    "# Elle contient la \"recette\" pour transformer chacune des colonnes\n",
    "# Sur les colonnes 1 et 2 qui sont de type numérique appliquer StandarScaler\n",
    "# Sur la colonne 0 qui est de type catégorielle, appliquer OneHotEncoder\n",
    "# ... \n",
    "# L'énorme avantage de procéder comme ça c'est que \n",
    "#     si on veut tester un ou ajouter des transformers sur des colonnes on peut le faire en modifiant le code à un seul endroit\n",
    "#     on est sûr d'appliquer la même \"recette\" plus tard à nos données de test (X_test)\n",
    "\n",
    "X_train = featureencoder.fit_transform(X_train)\n",
    "print(X_train[:5])  # print first 5 rows (not using iloc since now X_train became a numpy array)\n",
    "                    # ! X_train became a numpy array\n",
    "\n",
    "# On a 4 colonnes à l'affichage car il y a 2 pays, age et salary\n",
    "# France    => 0 et 0\n",
    "# Allemagne => 1 et 0\n",
    "# Spain     => 0 et 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 - Encode labels of y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     No\n",
      "4    Yes\n",
      "6     No\n",
      "9    Yes\n",
      "3     No\n",
      "1    Yes\n",
      "2     No\n",
      "5    Yes\n",
      "Name: Purchased, dtype: object\n",
      "[0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Encoding labels\n",
    "# Replace \"yes\" / \"no\" by `0` and `1` which can be interpreted by a computer. \n",
    "\n",
    "print(y_train)\n",
    "labelencoder = LabelEncoder()                       # LabelEncoder provient de sklearn.preprocessing\n",
    "                                                    # Va transformer les Yes, No en 0, 1\n",
    "                                                    # Si on avait eu Riri, Fifi, Loulou en lables différents\n",
    "                                                    # il aurait codé en 0, 1 et 2\n",
    "y_train = labelencoder.fit_transform(y_train)\n",
    "print(y_train[:5])                                  # print first 5 rows (not using iloc since now y_train became a numpy array)\n",
    "                                                    # ! y_train became a numpy array"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step X - Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 - Apply preprocessing to test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 - Missing values\n",
    "# print(X_test)\n",
    "# X_test = X_test.copy()                                          # !Z\n",
    "                                                                  # Semble plus nécessaire en 2023\n",
    "X_test.iloc[:,[1,2]] = imputer.transform(X_test.iloc[:,[1,2]])    # On réutilise l'objet imputer\n",
    "# print(X_test) \n",
    "\n",
    "# 5.2 - Encoding categorical features and standardizing numeric features\n",
    "X_test = featureencoder.transform(X_test)       # On réutilise la \"recette\" contenue dans l'objet featureencoder\n",
    "                                                # On est sûr et certains de traiter les données de test de la même façon que les données de training  \n",
    "# print(X_test)\n",
    "\n",
    "# 5.3 - Encoding labels\n",
    "# print(y_test)\n",
    "y_test = labelencoder.transform(y_test)         # On réutilise l'objet labelencoder\n",
    "# print(y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 - Predict and evaluate"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "216d08ced86f1f6e0b5764233bcb18334be12ba95b6ee555f60be9cf0be8c147"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

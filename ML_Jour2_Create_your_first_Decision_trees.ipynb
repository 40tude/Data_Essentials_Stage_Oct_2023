{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![crack](https://www.deltawines.eu/assets/files/shutterstock-532006042-72-1.1920x0.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine Grading\n",
    "\n",
    "Let's practice Decision Trees & Random Forest on a super cool dataset. We'll be trying to predict the quality of a given wine! \n",
    "\n",
    "Your goal will be to:\n",
    "\n",
    "1. Preprocess the data\n",
    "2. Create a classification algorithm\n",
    "\n",
    "Happy Coding!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Import Data ü§π‚Äç‚ôÄÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import usual librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import `Wine_grading.csv` and visualize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./assets/ML/Wine_grading.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove `Unnamed:0` column from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(columns=[\"Unnamed: 0\"], axis=1)\n",
    "df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - EDA üìä"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualize `alcohol` and `Grade`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data = df, x=\"Grade\", y=\"alcohol\", kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualize `magnesium` and `Grade`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data = df, x=\"Grade\", y=\"magnesium\", kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualize `color_intensity` and `Grade`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data = df, x=\"Grade\", y=\"color_intensity\", kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Show your dataset main statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's take a look to missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Preprocessing üç≥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split your dataset by $X$ and $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.loc[:,\"Grade\"]                                      \n",
    "\n",
    "# features_list = df.columns[:-1]\n",
    "# X = df.loc[:,features_list]\n",
    "X = df.drop(columns=[\"Grade\"])                             \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split your data in train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=0, \n",
    "                                                    stratify = y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make all the required preprocessings on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.head())                                               # print first 5 rows (not using iloc since now X_train became a numpy array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numeric_features = list(range(13)) \n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "feature_encoder = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features)\n",
    "        ]\n",
    "    )\n",
    "X_train = feature_encoder.fit_transform(X_train)\n",
    "print(X_train[0:5,0:3])                                               # print first 5 rows (not using iloc since now X_train became a numpy array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build your model üèãÔ∏è‚Äç‚ôÇÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- - Create your Logistic Regression model -->\n",
    "- Create your Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train, y_train)                  # This steps is the actual training\n",
    "y_train_pred = classifier.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluate it (don't forget to preprocess X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = feature_encoder.transform(X_test)\n",
    "y_test_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Look at your model scores on train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What can you say about it ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create the confusion matrix with `plot_confusion_matrix`\u001c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix on train set\n",
    "cm = confusion_matrix(y_train, y_train_pred, labels=classifier.classes_)\n",
    "cm_display = ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred)\n",
    "cm_display.ax_.set_title(\"Confusion matrix on train et \") \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://vitalflux.com/accuracy-precision-recall-f1-score-python-example/\n",
    "# Precision : Out of all the positive predicted, what percentage is truly positive. Spam\n",
    "# Recall    : Out of the total positive, what percentage are predicted positive.    Medicine, Credit card\n",
    "# F1        : Harmonic average Recall Precision \n",
    "\n",
    "# ! average='micro' ==> https://stackoverflow.com/questions/52269187/facing-valueerror-target-is-multiclass-but-average-binary\n",
    "# print(f\"Precision TP/(TP+FP) - Left col                  : {precision_score(y_train, y_train_pred, average='micro'):.3f}\" )\n",
    "# print(f\"Recall TP/(TP+FN)  - Bottom line                 : {recall_score(y_train, y_train_pred, average='micro'):.3f}\" )\n",
    "# print(f\"F1 2/(1/Prec + 1/Rec)                            : {f1_score(y_train, y_train_pred, average='micro'):.3f}\" )\n",
    "# print(f\"Accuracy (TP+TN)/(TP+FN+TN+FP) - Diag over total : {accuracy_score(y_train, y_train_pred):.3f}\" )\n",
    "print(f\"Accuracy on train set                            : {classifier.score(X_train, y_train):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix on test set\n",
    "cm = confusion_matrix(y_test, y_test_pred, labels=classifier.classes_)\n",
    "cm_display = ConfusionMatrixDisplay.from_predictions(y_test, y_test_pred)\n",
    "cm_display.ax_.set_title(\"Confusion matrix on test set \") \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://vitalflux.com/accuracy-precision-recall-f1-score-python-example/\n",
    "# Precision : Out of all the positive predicted, what percentage is truly positive. Credit card\n",
    "# Recall    : Out of the total positive, what percentage are predicted positive.    Spam\n",
    "# F1        : Harmonic average Recall Precision \n",
    "# print(f\"Precision TP/(TP+FP) - Left col                  : {precision_score(y_test, y_test_pred, average='micro'):.3f}\" )\n",
    "# print(f\"Recall TP/(TP+FN)  - Bottom line                 : {recall_score(y_test, y_test_pred, average='micro'):.3f}\" )\n",
    "# print(f\"F1 2/(1/Prec + 1/Rec)                            : {f1_score(y_test, y_test_pred, average='micro'):.3f}\" )\n",
    "# print(f\"Accuracy (TP+TN)/(TP+FN+TN+FP) - Diag over total : {accuracy_score(y_test, y_test_pred):.3f}\" )\n",
    "print(f\"Accuracy on test set                            : {classifier.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a dataframe with features importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Our model is overfitting. Let's try to play with parameters. Using [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html?highlight=decision%20tree#sklearn.tree.DecisionTreeClassifier) try to: \n",
    "    * Increase `min_samples_split`\n",
    "    * Play around with other parameters if you want to better optimize your model! üîß"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier(min_samples_split=80, class_weight=\"balanced\" )\n",
    "classifier.fit(X_train, y_train) \n",
    "y_train_pred = classifier.predict(X_train)\n",
    "y_test_pred = classifier.predict(X_test)\n",
    "\n",
    "# Plot confusion matrix on train set\n",
    "cm = confusion_matrix(y_train, y_train_pred, labels=classifier.classes_)\n",
    "cm_display = ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred)\n",
    "cm_display.ax_.set_title(\"Confusion matrix on train et \") \n",
    "plt.show() \n",
    "print(f\"Accuracy on train set                            : {classifier.score(X_train, y_train):.3f}\")\n",
    "\n",
    "# Plot confusion matrix on test set\n",
    "cm = confusion_matrix(y_test, y_test_pred, labels=classifier.classes_)\n",
    "cm_display = ConfusionMatrixDisplay.from_predictions(y_test, y_test_pred)\n",
    "cm_display.ax_.set_title(\"Confusion matrix on test set \") \n",
    "plt.show() \n",
    "print(f\"Accuracy on test set                            : {classifier.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus 1 - Feature Importance üèÑ‚Äç‚ôÇÔ∏è\n",
    "\n",
    "* Try to visualize feature importance of your decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame({\n",
    "    \"feature_names\": X.columns,\n",
    "    \"coefficients\": classifier.feature_importances_\n",
    "})\n",
    "print(feature_importance.sort_values(by=\"coefficients\", ascending=False))\n",
    "_ = feature_importance.sort_values(by=\"coefficients\", ascending=False).plot(kind=\"bar\", x=\"feature_names\", figsize=(16*.65, 9*.65))\n",
    "_ = plt.xticks(rotation=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus 2 - Try a Random Forest üèÑ‚Äç‚ôÇÔ∏è\n",
    "\n",
    "* Do you think a Random Forest can do better? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = RandomForestClassifier(n_estimators = 30)\n",
    "classifier = RandomForestClassifier(min_samples_split=80, class_weight=\"balanced\" )\n",
    "\n",
    "classifier.fit(X_train, y_train) \n",
    "y_train_pred = classifier.predict(X_train)\n",
    "y_test_pred = classifier.predict(X_test)\n",
    "\n",
    "# Plot confusion matrix on train set\n",
    "cm = confusion_matrix(y_train, y_train_pred, labels=classifier.classes_)\n",
    "cm_display = ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred)\n",
    "cm_display.ax_.set_title(\"Confusion matrix on train et \") \n",
    "plt.show() \n",
    "print(f\"Accuracy on train set                            : {classifier.score(X_train, y_train):.3f}\")\n",
    "\n",
    "# Plot confusion matrix on test set\n",
    "cm = confusion_matrix(y_test, y_test_pred, labels=classifier.classes_)\n",
    "cm_display = ConfusionMatrixDisplay.from_predictions(y_test, y_test_pred)\n",
    "cm_display.ax_.set_title(\"Confusion matrix on test set \") \n",
    "plt.show() \n",
    "print(f\"Accuracy on test set                            : {classifier.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus 3 [For the coding warriors] - Visualize your decision tree üèÑ‚Äç‚ôÇÔ∏è\n",
    "\n",
    "* Did you know that you can visualize an actual decision tree? \n",
    "    * Check out this [documentation](https://scikit-learn.org/stable/auto_examples/tree/plot_iris_dtc.html#sphx-glr-auto-examples-tree-plot-iris-dtc-py) and try to do it with your Decision \n",
    "    * Careful, it doesn't work for Random Forests üôè"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier(min_samples_split=80, class_weight=\"balanced\" )\n",
    "classifier.fit(X_train, y_train) \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30, 30)) # Resize figure\n",
    "plot_tree(classifier, filled = True, feature_names = list(X.columns), proportion = True, ax = ax)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "216d08ced86f1f6e0b5764233bcb18334be12ba95b6ee555f60be9cf0be8c147"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
